{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch\n",
    "\n",
    "In this tutorial, we will use PyTorch. A few words of introduction to what PyTorch does. We will dive into relevant portions of PyTorch in detail throughout this course.\n",
    "\n",
    "## What is PyTorch?\n",
    "\n",
    "PyTorch is a scientific computing (it is much more general than a toolbox for machine learning!) package developed primarily by Facebook.\n",
    "\n",
    "In this tutorial, let us look at the building blocks of PyTorch.\n",
    "\n",
    "This notebook is just a simple introduction. We'll delve deep into it as we go along..\n",
    "\n",
    "## Tensors\n",
    "\n",
    "Tensors are the core building blocks of PyTorch. Think of them like turbocharged `numpy.ndarray`. They run on GPUs and they come with more bells and whistles that a normal `numpy.ndarray` cannot do.\n",
    "\n",
    "Oh and they can track gradients and other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us initialize an empty uninitialized tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3539.7324,     0.0000,  3539.7324,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us construct a tensor with random values in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1034,  0.4959,  0.9990,  0.4371],\n",
      "        [ 0.8714,  0.8919,  0.6877,  0.2359],\n",
      "        [ 0.4840,  0.6405,  0.9767,  0.8828]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the size of the tensor that we defined in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.,  3.,  3.],\n",
      "        [ 3.,  3.,  3.]])\n",
      "tensor([[-2., -2., -2.],\n",
      "        [-2., -2., -2.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 3)\n",
    "b = torch.ones(2, 3)\n",
    "\n",
    "s = a + 2*b\n",
    "print(s)\n",
    "\n",
    "d = a - 3*b\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use standard NumPy-like indexing with all bells and whistles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2., -2.])\n"
     ]
    }
   ],
   "source": [
    "print(d[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2., -2., -2.])\n"
     ]
    }
   ],
   "source": [
    "print(d[1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "b_np = b.numpy()\n",
    "print(b_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of b <class 'torch.Tensor'>\n",
      "Type of b_np <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print('Type of b', type(b))\n",
    "print('Type of b_np', type(b_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  1.,  1.,  1.,  1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till now, it should not be a surprise for anyone used to `numpy`. Mostly, it has been functionining like `numpy`. Let us look at how they are different now.\n",
    "\n",
    "I mentioned earlier that they work on GPUs as well. \n",
    "\n",
    "Let us see how easy it is!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us check if your machine has GPU and CUDA is enabled. It is easily done using `torch.cuda.is_available()`.\n",
    "\n",
    "While we are at it, let us also look at how many GPUs we have. This is done using `torch.cuda.device_count()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A device is chosen using `torch.device(\"cuda\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1034,  1.4959,  1.9990,  1.4371],\n",
      "        [ 1.8714,  1.8919,  1.6877,  1.2359],\n",
      "        [ 1.4840,  1.6405,  1.9767,  1.8828]], device='cuda:0')\n",
      "tensor([[ 1.1034,  1.4959,  1.9990,  1.4371],\n",
      "        [ 1.8714,  1.8919,  1.6877,  1.2359],\n",
      "        [ 1.4840,  1.6405,  1.9767,  1.8828]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another useful shortcut worth knowing. \n",
    "\n",
    "Calling `.cuda()` on a tensor moves the tensors to the GPUs. For a lot of image classification exercises, computing on CPUs is extremely slow.\n",
    "\n",
    "`.cuda()` works on a lot of things - models, tensors etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.],\n",
       "        [ 1.,  1.]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones([2, 2])\n",
    "x.cuda()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lasio_torch]",
   "language": "python",
   "name": "conda-env-lasio_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
